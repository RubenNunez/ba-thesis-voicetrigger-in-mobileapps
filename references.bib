% Book: O'reilly: Aduio Programming with MATLAB
@book{tarr2018hackaudio,
	title        = {Hack audio : : an introduction to computer programming and digital signal processing in MATLAB},
	author       = {Tarr, Eric},
	booktitle    = {Hack audio : an introduction to computer programming and digital signal processing in MATLAB},
	publisher    = {Routledge},
	address      = {London},
	series       = {Audio Engineering Society presents},
	isbn         = {1-351-01845-0},
	abstract     = {
		Computers are at the center of almost everything related to audio. Whether for synthesis in music
		production, recording in the studio, or mixing in live sound, the computer plays an essential
		part. Audio effects plug-ins and virtual instruments are implemented as software computer code.
		Music apps are computer programs run on a mobile device. All these tools are created by
		programming a computer.  Hack Audio: An Introduction to Computer Programming and Digital Signal
		Processing in MATLAB provides an introduction for musicians and audio engineers interested in
		computer programming. It is intended for a range of readers including those with years of
		programming experience and those ready to write their first line of code. In the book, computer
		programming is used to create audio effects using digital signal processing. By the end of the
		book, readers implement the following effects: signal gain change, digital summing, tremolo,
		auto-pan, mid/side processing, stereo widening, distortion, echo, filtering, equalization,
		multi-band processing, vibrato, chorus, flanger, phaser, pitch shifter, auto-wah, convolution and
		algorithmic reverb, vocoder, transient designer, compressor, expander, and de-esser. Throughout
		the book, several types of test signals are synthesized, including: sine wave, square wave,
		sawtooth wave, triangle wave, impulse train, white noise, and pink noise. Common visualizations
		for signals and audio effects are created including: waveform, characteristic curve, goniometer,
		impulse response, step response, frequency spectrum, and spectrogram. In total, over 200 examples
		are provided with completed code demonstrations.
	},
	edition      = {1st edition},
	keywords     = {MATLAB},
	language     = {eng},
	date         = 2018
}

% Book: O'reilly: Fourier Analysis
@book{hansen2014fourier,
	title        = {Fourier Transforms: Principles and Applications},
	author       = {Hansen, Eric W.},
	publisher    = {Wiley},
	pages        = 776,
	date         = {2014-09},
	abstract     = {
		Fourier Transforms: Principles and Applications explains transform methods and their applications
		to electrical systems from circuits, antennas, and signal processors--ably guiding readers from
		vector space concepts through the Discrete Fourier Transform (DFT), Fourier series, and Fourier
		transform to other related transform methods. Featuring chapter end summaries of key results,
		over two hundred examples and four hundred homework problems, and a Solutions Manual this book is
		perfect for graduate students in signal processing and communications as well as practicing
		engineers. Class-tested at Dartmouth. Provides the same solid background as classic texts in the
		field, but with an emphasis on digital and other contemporary applications to signal and image
		processing. Modular coverage of material allows for topics to be covered by preference. MATLAB
		files and Solutions Manual available to instructors. Over 300 figures, 200 worked examples, and
		432 homework problems.
	},
	keywords     = {FinTech, Fourier Transforms, Signal Processing, Communications, Electrical Systems}
}

% Proposal: Audio C++ https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2019/p1386r2.pdf
@article{somberg2019audioapi,
	title        = {A Standard Audio API for C++: Motivation, Scope, and Basic Design},
	author       = {Somberg, Guy and Davidson, Guy and Doumler, Timur},
	journal      = {Programming Language C++},
	note         = {
		``C++ is there to deal with hardware at a low level, and to abstract away from it with zero
		overhead.'' – Bjarne Stroustrup, Cpp.chat Episode \#44
	},
	date         = {2019-06-17}
}

% Article: PCM -  https://ieeexplore.ieee.org/abstract/document/5212943
@article{deloraine1965pcm,
	title        = {The 25th anniversary of pulse code modulation},
	author       = {Deloraine, E. Maurice and Reeves, Alec H.},
	journal      = {IEEE Spectrum},
	volume       = 2,
	number       = 5,
	pages        = {56--63},
	doi          = {10.1109/MSPEC.1965.5212943},
	date         = 1965
}

# Blog: 
# https://dropsofai.com/understanding-audio-data-fourier-transform-fft-and-spectrogram-features-for-a-speech-recognition-system/
@online{chaudhary2020,
	title        = {
		Understanding Audio data, Fourier Transform, FFT and Spectrogram features for a Speech
		Recognition System
	},
	author       = {Kartik Chaudhary},
	url          = {
		https://dropsofai.com/understanding-audio-data-fourier-transform-fft-and-spectrogram-features-for-a-speech-recognition-system/
	},
	note         = {Zugriff am: 06.10.2023},
	date         = 2020
}

% Blog https://haythamfayek.com/2016/04/21/speech-processing-for-machine-learning.html
@misc{fayek2016,
	title        = {
		Speech Processing for Machine Learning: Filter banks, Mel-Frequency Cepstral Coefficients (MFCCs)
		and What's In-Between
	},
	author       = {Haytham M. Fayek},
	url          = {https://haythamfayek.com/2016/04/21/speech-processing-for-machine-learning.html},
	date         = 2016
}

% Video https://www.youtube.com/watch?v=zXd743X6I0w Fourier-Analysis in 100 Minuten
@online{weitz2023fourier,
	title        = {Fourier-Analysis in 100 Minuten},
	author       = {Prof. Dr. Edmund Weitz},
	publisher    = {Weitz / HAW Hamburg},
	url          = {https://www.youtube.com/watch?v=zXd743X6I0w},
	note         = {Zugriff am: 06.10.2023},
	date         = 2023,
	organization = {YouTube},
	type         = {Video}
}

# Paper: https://arxiv.org/abs/2108.00084
@misc{hannun2021history,
	title        = {The History of Speech Recognition to the Year 2030},
	author       = {Awni Hannun},
	date         = 2021,
	eprint       = {2108.00084},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL}
}

# Blog: Porcupine Wake Word Detection
@online{picovoice2023porcupine,
	title        = {Porcupine -- Train custom wake words in seconds.},
	author       = {Picovoice},
	year         = 2023,
	url          = {https://picovoice.ai/platform/porcupine/},
	note         = {Zugriff am 10. Oktober 2023}
}

# Paper: https://openarchive.nure.ua/items/cc1c316e-fa03-437f-855d-8e699339f1d5
@article{matarneh2017speechrecognition,
	title        = {Speech Recognition Systems: A Comparative Review},
	author       = {Matarneh, Rami and Maksymova, Svitlana and Lyashenko, Vyacheslav V. and Belova, Nataliya V.},
	journal      = {OSR Journal of Computer Engineering (IOSR-JCE)},
	volume       = 19,
	number       = 5,
	pages        = {71--79},
	doi          = {10.9790/0661-1905047179},
	issn         = {e-ISSN: 2278-0661, p-ISSN: 2278-8727},
	url          = {http://www.iosrjournals.org},
	note         = {Submission Date: 13-10-2017, Acceptance Date: 27-10-2017},
	date         = 2017,
	abstract     = {
		Creating voice control for robots is very important and difficult task. Therefore, we consider
		different systems of speech recognition. We divided them into two main classes: (1) open-source
		and (2) close-source code. As close-source software the following were selected: Dragon Mobile
		SDK, Google Speech Recognition API, Siri, Yandex SpeechKit and Microsoft Speech API. While the
		following were selected as open-source software: CMU Sphinx, Kaldi, Julius, HTK, iAtros, RWTH ASR
		and Simon. The comparison mainly based on accuracy, API, performance, speed in real-time,
		response time and compatibility. the variety of comparison axes allow us to make detailed
		description of the differences and similarities, which in turn enabled us to adopt a careful
		decision to choose the appropriate system depending on our need. Keywords: Robot, Speech
		recognition, Voice systems with closed source code, Voice systems with open source code
	}
}

# Book: Deep Learning from Scratch 
@book{weidman2019deep,
	title        = {Deep learning from scratch : : building with Python from first principles},
	author       = {Weidman, Seth},
	year         = 2019,
	booktitle    = {Deep learning from scratch : building with Python from first principles},
	publisher    = {O'Reilly},
	address      = {Beijing},
	isbn         = {1-4920-4136-X},
	abstract     = {
		With the resurgence of neural networks in the 2010s, understanding deep learning has become
		essential for machine learning practitioners and even many software engineers.  This practical
		book provides a thorough introduction for data scientists and software engineers with previous
		exposure to machine learning. You'll start with deep learning basics and move quickly to the
		details of important advanced architectures, implementing everything from scratch along the way.
		Author Seth Weidman shows you how neural networks function using a first principles approach.
		You'll learn how to apply multilayer neural networks, convolutional neural networks, and
		recurrent neural networks from the ground up.  With a detailed understanding of how these
		networks work mathematically, computationally, and conceptually, you'll be set up for success on
		future deep learning projects.
	},
	edition      = {First edition.},
	keywords     = {Python (Computer program language)},
	language     = {eng}
}

# Blog: Hey Siri Feature
@online{siri2017hey,
	title        = {Hey Siri: An On-device DNN-powered Voice Trigger for Apple's Personal Assistant},
	author       = {Siri-Team},
	journal      = {Apple Machine Learning Journal},
	url          = {https://machinelearning.apple.com/research/hey-siri},
	note         = {Zugriffsdatum: 10. September 2023},
	date         = {2017-10}
}

# Blog: Voice Trigger System for Siri
@online{apple2023voice,
	title        = {Voice Trigger System for Siri},
	author       = {Machine Learning Journal Apple},
	journal      = {Apple Machine Learning Journal},
	url          = {https://machinelearning.apple.com/research/voice-trigger},
	note         = {Zugriffsdatum: 10. September 2023},
	date         = {2023-08},
	abstract     = {
		A growing number of consumer devices, including smart speakers, headphones, and watches, use
		speech as the primary means of user input. Voice trigger detection systems have become an
		important component of the user interaction pipeline. This article discusses Apple's design of a
		high-accuracy, on-device voice trigger system.
	}
}


# Mozilla Common Voice Dataset: https://arxiv.org/abs/1912.06670
@misc{ardila2020common,
	title        = {Common Voice: A Massively-Multilingual Speech Corpus},
	author       = {
		Rosana Ardila and Megan Branson and Kelly Davis and Michael Henretty and Michael Kohler and Josh
		Meyer and Reuben Morais and Lindsay Saunders and Francis M. Tyers and Gregor Weber
	},
	year         = 2020,
	eprint       = {1912.06670},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL}
}

# Paper: wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations
@misc{baevski2020wav2vec,
	title        = {wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations},
	author       = {Alexei Baevski and Henry Zhou and Abdelrahman Mohamed and Michael Auli},
	year         = 2020,
	eprint       = {2006.11477},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL}
}

# Paper: Augmented Datasheets for Speech Datasets and Ethical Decision-Making
@inproceedings{papakyriakopoulos2023augmented,
	title        = {Augmented Datasheets for Speech Datasets and Ethical Decision-Making},
	author       = {
		Orestis Papakyriakopoulos and Anna Seo Gyeong Choi and William Thong and Dora Zhao and Jerone
		Andrews and Rebecca Bourke and Alice Xiang and Allison Koenecke
	},
	year         = 2023,
	booktitle    = {2023 {ACM} Conference on Fairness, Accountability, and Transparency},
	publisher    = {ACM},
	doi          = {10.1145/3593013.3594049},
	url          = {https://doi.org/10.1145\%2F3593013.3594049}
}

# Paper: A Survey of Deep Learning for Scientific Discovery
@inproceedings{khamees2021classifying,
	title        = {Classifying Audio Music Genres Using CNN and RNN},
	author       = {Khamees, Ahmed A. and Hejazi, Hani D. and Alshurideh, Muhammad and Salloum, Said A.},
	year         = 2021,
	booktitle    = {Advanced Machine Learning Technologies and Applications},
	publisher    = {Springer International Publishing},
	address      = {Cham},
	pages        = {315--323},
	isbn         = {978-3-030-69717-4},
	abstract     = {
		This paper discusses applying different types of neural networks to classify a dataset of type
		audio. We used a GTZAN dataset that includes various audio music records representing different
		conventional categories of music genres. Each shares a set of common traditions; these traditions
		we call features. We build our proposed Python models using the Anaconda toolkit with TensorFlow
		(TF) an open-source deep-learning library. In our previous research, we build a multilayer
		sequential model to classify the dataset and then solve the overfitting issue in that model. In
		this paper, we build a Convolutional Neural Network (CNN) and Recurrent Neural Network (RNN) with
		Long Short Time Memory (LSTM). Finally, we compared the results to know the capabilities and
		limitations of Deep Learning (DL). CNN outperformed the other models in terms of training and
		test accuracy, having 83.74{\%} and 74{\%}, respectively.
	},
	editor       = {Hassanien, Aboul-Ella and Chang, Kuo-Chi and Mincong, Tang}
}

# Github: Hey Ditto Activation Model
@online{barazanji2023heyditto,
	title        = {Hey Ditto Activation Model},
	author       = {Barazanji, Omar and Spencer, Peyton},
	journal      = {GitHub repository},
	url          = {url{https://github.com/omarzanji/ditto\%5Factivation}},
	note         = {Zugriffsdatum: 10. Oktober 2023},
	date         = {2023-10}
}

# Medium: Battle of The Giants: TensorFlow vs PyTorch 2023
@misc{valantis2023battle,
  author = {Valantis, K.},
  title = {Battle of The Giants: TensorFlow vs PyTorch 2023},
  year = {2023},
  howpublished = {Medium},
  note = {\url{https://medium.com/@valkont/battle-of-the-giants-tensorflow-vs-pytorch-2023-fd8274210a38} [Zugriff 5. November 2023]},
  month = jan,
  day = {28},
  readtime = {3 min read}
}


@misc{lim2023lightweight,
      title={Lightweight feature encoder for wake-up word detection based on self-supervised speech representation}, 
      author={Hyungjun Lim and Younggwan Kim and Kiho Yeom and Eunjoo Seo and Hoodong Lee and Stanley Jungkyu Choi and Honglak Lee},
      year={2023},
      eprint={2303.07592},
      archivePrefix={arXiv},
      primaryClass={eess.AS},
      note = {\url{https://arxiv.org/abs/2303.07592} [Zugriff 15. Oktober 2023]},
}

@online{huggingface2023finetune,
  author = {{Hugging Face}},
  title = {Fine-tune a pretrained model},
  year = 2023,
  url = {https://huggingface.co/docs/transformers/training},
  urldate = {2023-11-21},
  note = {Zugriff am 21. November 2023},
  organization = {Hugging Face},
  series = {Tutorials}
}



# -------------- NOT USED ----------------------

# Dataset: Speech Commands Dataset https://arxiv.org/abs/1804.03209
@misc{warden2018speech,
	title        = {Speech Commands: A Dataset for Limited-Vocabulary Speech Recognition},
	author       = {Pete Warden},
	date         = 2018,
	eprint       = {1804.03209},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL}
}

# Paper MIR: https://arxiv.org/abs/1709.04396
@misc{choi2018tutorial,
	title        = {A Tutorial on Deep Learning for Music Information Retrieval},
	author       = {Keunwoo Choi and György Fazekas and Kyunghyun Cho and Mark Sandler},
	year         = 2018,
	eprint       = {1709.04396},
	archiveprefix = {arXiv},
	primaryclass = {cs.CV}
}

# Paper: Facebooks wav2vec2 https://arxiv.org/abs/2006.11477
@misc{baevski2020wav2vec,
	title        = {wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations},
	author       = {Alexei Baevski and Henry Zhou and Abdelrahman Mohamed and Michael Auli},
	year         = 2020,
	eprint       = {2006.11477},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL}
}
